{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "589f7e09-d1c3-4b57-801c-62e041a0a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4096f51-91e7-46dd-8f43-2672bc90e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinIO Storage Settings\n",
    "MINIO_ENDPOINT = os.getenv(\"AWS_S3_ENDPOINT\")\n",
    "MINIO_ACCESS_KEY = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "MINIO_SECRET_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "LOGS_BUCKET = \"logs\"\n",
    "REPORTS_BUCKET = \"report\"\n",
    "PLAYBOOKS_BUCKET = \"playbook\"\n",
    "LOG_FILE = \"service_error_down.txt\" # This variable will be used throughout the script\n",
    "\n",
    "# LLM Info\n",
    "INFERENCE_ENDPOINT = \"https://granite-aiops.apps.cluster-hdmxf.hdmxf.sandbox689.opentlc.com\"\n",
    "MODEL_API_URL = f\"{INFERENCE_ENDPOINT}/v1/completions\"\n",
    "MODEL_NAME = \"granite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c06fe986-580f-47ee-830f-ad4cf4c832bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "AIOps PIPELINE STAGE: Generate Remediation Playbook\n",
      "==============================================\n",
      "\n",
      "--> Step 1: Extracting and saving keywords...\n",
      "    ✅ Extracted Host: 'aiops', Service: 'httpd', Port: 80\n",
      "    ✅ Successfully saved keywords to 'extracted_keywords.json'.\n",
      "\n",
      "--> Step 2: Querying AI model for playbook steps (JSON)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'granite-aiops.apps.cluster-hdmxf.hdmxf.sandbox689.opentlc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✅ AI-generated task data received and parsed successfully.\n",
      "\n",
      "--> Step 3: Constructing final playbook from structured data...\n",
      "    ✅ Final playbook constructed successfully.\n",
      "\n",
      "--> Uploading 'remediation_playbook_20250617_130407.yml' to bucket 'playbook'...\n",
      "    ✅ Successfully uploaded 'remediation_playbook_20250617_130407.yml'.\n",
      "\n",
      "--- FINAL ACTIONABLE PLAYBOOK ---\n",
      "- name: Restore HTTPD Service\n",
      "  hosts: aiops\n",
      "  become: true\n",
      "  vars:\n",
      "    max_retries: 3\n",
      "    retry_delay: 10\n",
      "    service: httpd\n",
      "    port: 80\n",
      "  tasks:\n",
      "  - name: Start the HTTP server service\n",
      "    ansible.builtin.service:\n",
      "      name: httpd\n",
      "      state: started\n",
      "      enabled: true\n",
      "  - name: Check the status of the HTTP server service\n",
      "    ansible.builtin.service:\n",
      "      name: httpd\n",
      "      state: status\n",
      "  - name: Verify that the HTTP server is listening on Port 80\n",
      "    ansible.builtin.command:\n",
      "      cmd: ss -tln | grep 80\n",
      "\n",
      "\n",
      "==============================================\n",
      "                   STAGE COMPLETE\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_and_save_keywords(report_filename=\"incident_report.txt\", output_filename=\"extracted_keywords.json\"):\n",
    "    \"\"\"Reads the full report, extracts keywords, and saves them to a new file.\"\"\"\n",
    "    print(f\"\\n--> Step 1: Extracting and saving keywords...\")\n",
    "    details = {}\n",
    "    try:\n",
    "        with open(report_filename, 'r', encoding='utf-8') as f:\n",
    "            report_text = f.read()\n",
    "            \n",
    "        host_pattern = re.search(r\"AFFECTED HOST:\\s*(.*)\", report_text, re.IGNORECASE)\n",
    "        service_pattern = re.search(r\"AFFECTED SERVICE:\\s*(.*)\", report_text, re.IGNORECASE)\n",
    "        port_pattern = re.search(r\"port (\\d+)\", report_text, re.IGNORECASE)\n",
    "\n",
    "        if host_pattern:\n",
    "            details[\"host\"] = host_pattern.group(1).strip().strip('*').strip()\n",
    "        if service_pattern:\n",
    "            raw_service = service_pattern.group(1).strip().strip('*').strip()\n",
    "            details[\"service\"] = raw_service.replace('.service', '') if raw_service.endswith('.service') else raw_service\n",
    "            \n",
    "        details[\"port\"] = 80\n",
    "        if port_pattern:\n",
    "            details[\"port\"] = int(port_pattern.group(1))\n",
    "            \n",
    "        if \"host\" in details and \"service\" in details:\n",
    "            print(f\"    ✅ Extracted Host: '{details['host']}', Service: '{details['service']}', Port: {details['port']}\")\n",
    "            with open(output_filename, 'w') as out_f:\n",
    "                json.dump(details, out_f, indent=4)\n",
    "            print(f\"    ✅ Successfully saved keywords to '{output_filename}'.\")\n",
    "            return details\n",
    "            \n",
    "        print(\"    ❌ Failed to extract keywords.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"    ❌ Error: The file '{report_filename}' was not found. Please ensure the first pipeline stage has run.\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ An error occurred during keyword extraction: {e}\")\n",
    "    return None\n",
    "\n",
    "def query_model_for_playbook_steps(incident_report_filename=\"incident_report.txt\"):\n",
    "    \"\"\"Queries the AI model to generate a JSON object describing the playbook tasks.\"\"\"\n",
    "    print(f\"\\n--> Step 2: Querying AI model for playbook steps (JSON)...\")\n",
    "    try:\n",
    "        with open(incident_report_filename, 'r', encoding='utf-8') as f:\n",
    "            report_content = f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error reading report file '{incident_report_filename}': {e}\")\n",
    "        return None\n",
    "        \n",
    "    prompt = f\"\"\"\n",
    "Based on the full incident report below, generate a JSON object containing a list of Ansible tasks for remediation.\n",
    "Each task in the JSON list should be an object with three keys: \"name\" (a string for the task description), \"module\" (a string for the Ansible module, e.g., \"ansible.builtin.service\"), and \"args\" (an object of key-value pairs for the module's arguments).\n",
    "\n",
    "**Full Incident Report for Context:**\n",
    "---\n",
    "{report_content}\n",
    "---\n",
    "\n",
    "**Example of a valid JSON response format:**\n",
    "{{\n",
    "  \"tasks\": [\n",
    "    {{\n",
    "      \"name\": \"Ensure httpd is installed\",\n",
    "      \"module\": \"ansible.builtin.dnf\",\n",
    "      \"args\": {{\n",
    "        \"name\": \"httpd\",\n",
    "        \"state\": \"present\"\n",
    "      }}\n",
    "    }},\n",
    "    {{\n",
    "      \"name\": \"Start and enable httpd service\",\n",
    "      \"module\": \"ansible.builtin.service\",\n",
    "      \"args\": {{\n",
    "        \"name\": \"httpd\",\n",
    "        \"state\": \"started\",\n",
    "        \"enabled\": true\n",
    "      }}\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\"\"\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\"model\": MODEL_NAME, \"prompt\": prompt, \"max_tokens\": 2048}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(MODEL_API_URL, headers=headers, json=payload, verify=False)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        if 'choices' in result and result['choices']:\n",
    "            response_text = result['choices'][0].get('text', '').strip()\n",
    "            \n",
    "            # Find the JSON object within the response text\n",
    "            json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_string = json_match.group(0)\n",
    "                # **FIX**: Use `strict=False` to allow unescaped control characters within the JSON strings.\n",
    "                task_data = json.loads(json_string, strict=False)\n",
    "                print(\"    ✅ AI-generated task data received and parsed successfully.\")\n",
    "                return task_data.get(\"tasks\", [])\n",
    "            else:\n",
    "                print(\"    ❌ No valid JSON object found in AI response.\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error generating or parsing playbook tasks from AI model: {e}\")\n",
    "    return None\n",
    "\n",
    "def construct_final_playbook(tasks_list, keywords):\n",
    "    \"\"\"Constructs the final playbook by combining the static header and the AI-generated tasks.\"\"\"\n",
    "    print(\"\\n--> Step 3: Constructing final playbook from structured data...\")\n",
    "    \n",
    "    header = {\n",
    "        'name': f\"Restore {keywords.get('service', 'service').upper()} Service\",\n",
    "        'hosts': keywords.get('host'),\n",
    "        'become': True,\n",
    "        'vars': {\n",
    "            'max_retries': 3,\n",
    "            'retry_delay': 10,\n",
    "            'service': keywords.get('service'),\n",
    "            'port': keywords.get('port')\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Reconstruct the tasks in the correct Ansible format from the JSON data\n",
    "    ansible_tasks = []\n",
    "    for task in tasks_list:\n",
    "        # The module name becomes the key, and its args become the value\n",
    "        ansible_tasks.append({\n",
    "            'name': task.get('name'),\n",
    "            task.get('module'): task.get('args', {})\n",
    "        })\n",
    "\n",
    "    try:\n",
    "        # Combine the header and the reconstructed tasks\n",
    "        final_playbook_data = [{**header, 'tasks': ansible_tasks}]\n",
    "        final_playbook_yaml = yaml.dump(final_playbook_data, sort_keys=False, indent=2)\n",
    "        print(\"    ✅ Final playbook constructed successfully.\")\n",
    "        return final_playbook_yaml\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error constructing final playbook from AI response: {e}\")\n",
    "    return None\n",
    "\n",
    "def upload_to_minio(s3_client, bucket, object_name, content):\n",
    "    \"\"\"Uploads content to a specified MinIO bucket.\"\"\"\n",
    "    print(f\"\\n--> Uploading '{object_name}' to bucket '{bucket}'...\")\n",
    "    try:\n",
    "        s3_client.put_object(Body=content.encode('utf-8'), Bucket=bucket, Key=object_name)\n",
    "        print(f\"    ✅ Successfully uploaded '{object_name}'.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error uploading to MinIO: {e}\")\n",
    "    return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the AIOps workflow.\"\"\"\n",
    "    clean_endpoint = MINIO_ENDPOINT.replace(\"http://\", \"\").replace(\"https://\", \"\")\n",
    "    endpoint_url_with_protocol = f\"http://{clean_endpoint}\"\n",
    "    \n",
    "    s3_client = boto3.client(\n",
    "    's3', \n",
    "    endpoint_url=endpoint_url_with_protocol, \n",
    "    aws_access_key_id=MINIO_ACCESS_KEY, \n",
    "    aws_secret_access_key=MINIO_SECRET_KEY\n",
    "    )\n",
    "    \n",
    "    keywords = extract_and_save_keywords()\n",
    "    if not keywords:\n",
    "        sys.exit(\"Pipeline stopped: Failed to extract keywords.\")\n",
    "        \n",
    "    playbook_steps = query_model_for_playbook_steps()\n",
    "    print(playbook_steps)\n",
    "    if not playbook_steps: sys.exit(\"Pipeline stopped: Could not generate playbook steps.\")\n",
    "\n",
    "    final_playbook = construct_final_playbook(playbook_steps, keywords)\n",
    "    if not final_playbook: sys.exit(\"Pipeline stopped: Could not construct final playbook.\")\n",
    "\n",
    "        \n",
    "    if not upload_to_minio(s3_client, PLAYBOOKS_BUCKET, f\"remediation_playbook_{datetime.now().strftime('%Y%m%d_%H%M%S')}.yml\", final_playbook):\n",
    "        sys.exit(\"Pipeline stopped: Failed to upload playbook.\")\n",
    "\n",
    "    print(\"\\n--- FINAL ACTIONABLE PLAYBOOK ---\")\n",
    "    print(final_playbook)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"==============================================\")\n",
    "    print(\"AIOps PIPELINE STAGE: Generate Remediation Playbook\")\n",
    "    print(\"==============================================\")\n",
    "    main()\n",
    "    print(\"\\n==============================================\")\n",
    "    print(\"                   STAGE COMPLETE\")\n",
    "    print(\"==============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a9ebfe-d243-4a43-8818-d44f8ce0111c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe7d054-f24f-4f17-946a-8ba8aa13b5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c5813b-7c28-4376-baa2-f3c9f342f17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd9aec-a643-463a-9bb5-f4478c52486a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab609cec-301b-4f6c-81ba-890be7807c98",
   "metadata": {},
   "source": [
    "## Problems solved \n",
    "\n",
    "1. invalid control character\n",
    "\n",
    "\n",
    "   a. a very specific and common issue when working with AI-generated JSON. It happens because the AI model sometimes includes invisible characters, like newlines or tabs, inside the JSON strings it creates, which causes the standard Python JSON parser to fail.\n",
    "\n",
    "   b. Updated version will tell the JSON parser to be less strict and to allow these control characters\n",
    "\n",
    "\n",
    "2. incomplete generation (\"ansible.builtin.servi\")\n",
    "\n",
    "    a. The AI is outputting this:\n",
    "\n",
    "              ansible.builtin.\n",
    "            \n",
    "            service:\n",
    "            \n",
    "            \n",
    "        But valid YAML requires this:\n",
    "        \n",
    "              ansible.builtin.service:\n",
    "\n",
    "\n",
    "    b. Updated prompt will now include a very explicit instruction not to break module names across multiple lines. \n",
    "\n",
    "3.  * characters : error constructing final playbook... expected alphabetic or numeric character, but found '*' confirms this. The YAML parser sees the * from the markdown bolding and stops because it's not valid YAML.\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6fdc4-f9ee-4024-993c-94bd3433a6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bca479c-8739-4f49-952c-97f21d529593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

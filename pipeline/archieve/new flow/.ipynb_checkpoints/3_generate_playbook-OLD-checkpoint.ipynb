{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589f7e09-d1c3-4b57-801c-62e041a0a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4096f51-91e7-46dd-8f43-2672bc90e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinIO Storage Settings\n",
    "MINIO_ENDPOINT = os.getenv(\"AWS_S3_ENDPOINT\")\n",
    "MINIO_ACCESS_KEY = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "MINIO_SECRET_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "LOGS_BUCKET = \"logs\"\n",
    "REPORTS_BUCKET = \"report\"\n",
    "PLAYBOOKS_BUCKET = \"playbook\"\n",
    "LOG_FILE = \"service_error_down.txt\" # This variable will be used throughout the script\n",
    "INCIDENT_REPORT_FILE = \"incident_report.txt\"\n",
    "\n",
    "# LLM Info\n",
    "INFERENCE_ENDPOINT = \"https://granite-aiops.apps.cluster-hdmxf.hdmxf.sandbox689.opentlc.com\"\n",
    "MODEL_API_URL = f\"{INFERENCE_ENDPOINT}/v1/completions\"\n",
    "MODEL_NAME = \"granite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c06fe986-580f-47ee-830f-ad4cf4c832bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_keywords(report_filename=\"report.json\", output_filename=\"extracted_keywords.json\"):\n",
    "    \"\"\"Reads the full report, extracts keywords, and saves them to a new file.\"\"\"\n",
    "    print(f\"\\n--> Step 1: Extracting keywords from '{report_filename}'...\")\n",
    "    try:\n",
    "        with open(report_filename, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        report_content = data.get(\"report_content\")\n",
    "\n",
    "        details = {}\n",
    "        host_pattern = re.search(r\"AFFECTED HOST:\\s*(.*)\", report_content, re.IGNORECASE)\n",
    "        service_pattern = re.search(r\"AFFECTED SERVICE:\\s*(.*)\", report_content, re.IGNORECASE)\n",
    "\n",
    "        if host_pattern:\n",
    "            clean_host = host_pattern.group(1).strip().strip('*').strip()\n",
    "            details[\"affected_host\"] = clean_host\n",
    "        if service_pattern:\n",
    "            raw_service = service_pattern.group(1).strip().strip('*').strip()\n",
    "            details[\"affected_service\"] = raw_service.replace('.service', '') if raw_service.endswith('.service') else raw_service\n",
    "            \n",
    "        if \"affected_host\" in details and \"affected_service\" in details:\n",
    "            print(f\"    ✅ Extracted Host:    '{details['affected_host']}'\")\n",
    "            print(f\"    ✅ Affected Service: '{details['affected_service']}'\")\n",
    "            \n",
    "            with open(output_filename, 'w') as out_f:\n",
    "                json.dump(details, out_f, indent=4)\n",
    "            print(f\"    ✅ Successfully saved keywords to '{output_filename}'.\")\n",
    "            return details\n",
    "        else:\n",
    "            print(\"    ❌ Failed to extract keywords.\")\n",
    "            return None\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"    ❌ Error: The file '{report_filename}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ An error occurred during keyword extraction: {e}\")\n",
    "    return None\n",
    "\n",
    "def generate_ansible_playbook(host, service):\n",
    "    \"\"\"Generates a detailed Ansible playbook in YAML format.\"\"\"\n",
    "    print(f\"\\n--> Step 2: Generating Ansible playbook...\")\n",
    "    \n",
    "    # This dictionary structure represents the desired Ansible Playbook format.\n",
    "    playbook_data = [\n",
    "        {\n",
    "            'name': 'Restore HTTPD Service',\n",
    "            'hosts': host,\n",
    "            'become': True,\n",
    "            'vars': {\n",
    "                'max_retries': 3,\n",
    "                'retry_delay': 10\n",
    "            },\n",
    "            'tasks': [\n",
    "                {\n",
    "                    'name': f'Ensure {service} is installed',\n",
    "                    'ansible.builtin.dnf': {\n",
    "                        'name': service,\n",
    "                        'state': 'present'\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'name': f'Start and enable {service} service',\n",
    "                    'ansible.builtin.service': {\n",
    "                        'name': service,\n",
    "                        'state': 'started',\n",
    "                        'enabled': True\n",
    "                    },\n",
    "                    'register': 'svc_result',\n",
    "                    'until': 'svc_result is succeeded',\n",
    "                    'retries': '{{ max_retries }}',\n",
    "                    'delay': '{{ retry_delay }}'\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Ensure port 80 is open',\n",
    "                    'ansible.posix.firewalld': {\n",
    "                        'port': '80/tcp',\n",
    "                        'state': 'enabled',\n",
    "                        'permanent': True,\n",
    "                        'immediate': True\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Verify service recovery',\n",
    "                    'ansible.builtin.uri': {\n",
    "                        'url': 'http://localhost',\n",
    "                        'status_code': 200\n",
    "                    },\n",
    "                    'register': 'verify',\n",
    "                    'until': 'verify.status == 200',\n",
    "                    'retries': '{{ max_retries }}',\n",
    "                    'delay': '{{ retry_delay }}'\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        yaml_output = yaml.dump(playbook_data, sort_keys=False, indent=2)\n",
    "        print(\"    ✅ Ansible Playbook generated successfully.\")\n",
    "        return yaml_output\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error generating YAML: {e}\")\n",
    "        return None\n",
    "\n",
    "def upload_to_minio(s3_client, bucket, object_name, content):\n",
    "    \"\"\"Uploads content to a specified MinIO bucket.\"\"\"\n",
    "    print(f\"--> Uploading '{object_name}' to bucket '{bucket}'...\")\n",
    "    try:\n",
    "        s3_client.put_object(Body=content.encode('utf-8'), Bucket=bucket, Key=object_name)\n",
    "        print(f\"    ✅ Successfully uploaded '{object_name}'.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error uploading to MinIO: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45e570a7-510b-4d60-b637-48656784f043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "AIOps PIPELINE STAGE: Generate Remediation Playbook\n",
      "==============================================\n",
      "\n",
      "--> Step 1: Extracting keywords from 'report.json'...\n",
      "    ✅ Extracted Host:    'aiops'\n",
      "    ✅ Affected Service: 'httpd'\n",
      "    ✅ Successfully saved keywords to 'extracted_keywords.json'.\n",
      "\n",
      "--> Step 6: Generating Ansible playbook...\n",
      "    ✅ Ansible Playbook generated successfully.\n",
      "--> Uploading 'remediation_playbook_20250616_103845.yml' to bucket 'playbook'...\n",
      "    ✅ Successfully uploaded 'remediation_playbook_20250616_103845.yml'.\n",
      "\n",
      "--- FINAL ACTIONABLE PLAYBOOK ---\n",
      "- name: Restore HTTPD Service\n",
      "  hosts: aiops\n",
      "  become: true\n",
      "  vars:\n",
      "    max_retries: 3\n",
      "    retry_delay: 10\n",
      "  tasks:\n",
      "  - name: Ensure httpd is installed\n",
      "    ansible.builtin.dnf:\n",
      "      name: httpd\n",
      "      state: present\n",
      "  - name: Start and enable httpd service\n",
      "    ansible.builtin.service:\n",
      "      name: httpd\n",
      "      state: started\n",
      "      enabled: true\n",
      "    register: svc_result\n",
      "    until: svc_result is succeeded\n",
      "    retries: '{{ max_retries }}'\n",
      "    delay: '{{ retry_delay }}'\n",
      "  - name: Ensure port 80 is open\n",
      "    ansible.posix.firewalld:\n",
      "      port: 80/tcp\n",
      "      state: enabled\n",
      "      permanent: true\n",
      "      immediate: true\n",
      "  - name: Verify service recovery\n",
      "    ansible.builtin.uri:\n",
      "      url: http://localhost\n",
      "      status_code: 200\n",
      "    register: verify\n",
      "    until: verify.status == 200\n",
      "    retries: '{{ max_retries }}'\n",
      "    delay: '{{ retry_delay }}'\n",
      "\n",
      "\n",
      "==============================================\n",
      "            STAGE COMPLETE\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    s3_client = boto3.client(\n",
    "    's3', \n",
    "    endpoint_url=MINIO_ENDPOINT, \n",
    "    aws_access_key_id=MINIO_ACCESS_KEY, \n",
    "    aws_secret_access_key=MINIO_SECRET_KEY\n",
    "    )\n",
    "    \n",
    "    keywords = extract_and_save_keywords()\n",
    "    if not keywords:\n",
    "        sys.exit(\"Pipeline stopped: Failed to extract keywords.\")\n",
    "        \n",
    "    ansible_playbook = generate_ansible_playbook(keywords.get(\"affected_host\"), keywords.get(\"affected_service\"))\n",
    "    if not ansible_playbook:\n",
    "        sys.exit(\"Pipeline stopped: Could not generate playbook.\")\n",
    "        \n",
    "    if not upload_to_minio(s3_client, PLAYBOOKS_BUCKET, f\"remediation_playbook_{datetime.now().strftime('%Y%m%d_%H%M%S')}.yml\", ansible_playbook):\n",
    "        sys.exit(\"Pipeline stopped: Failed to upload playbook.\")\n",
    "\n",
    "    print(\"\\n--- FINAL ACTIONABLE PLAYBOOK ---\")\n",
    "    print(ansible_playbook)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"==============================================\")\n",
    "    print(\"AIOps PIPELINE STAGE: Generate Remediation Playbook\")\n",
    "    print(\"==============================================\")\n",
    "    main()\n",
    "    print(\"\\n==============================================\")\n",
    "    print(\"            STAGE COMPLETE\")\n",
    "    print(\"==============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c07196-82fc-4a61-a1b4-21bb817736a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
